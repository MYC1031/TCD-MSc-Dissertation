{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##anticancer合成数据评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Cancer Type One-letter amino-acid sequence               class\n",
      "0    Lung Cancer             KWKLFKKIPKFLHLAKKF  inactive - virtual\n",
      "1    Lung Cancer                   PEDAEAIAKQIN  inactive - virtual\n",
      "2  Breast Cancer               FAKKLAKLAKKLAKKL  inactive - virtual\n",
      "3    Lung Cancer         KWKLFKKIGIGKLKFLHLAKKF  inactive - virtual\n",
      "4    Lung Cancer                   FELVESVVVRRR  inactive - virtual\n",
      "Logistic Regression Accuracy: 0.875\n",
      "Decision Tree Accuracy: 0.84\n",
      "Random Forest Accuracy: 0.805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/guoquanjiang/envs/begreat/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/sample_data/Health & Medicine/anticancer_samples.csv')\n",
    "# data = pd.read_csv('/data/guoquanjiang/be_great/sample_data/california_samples.csv')\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class']\n",
    "# Encode categorical features with Label Encoding\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode target column if it is categorical\n",
    "if y.dtype == 'object':\n",
    "    target_le = LabelEncoder()\n",
    "    y = target_le.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=100)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy}')\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(max_depth=10)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(max_depth=12, n_estimators=75)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "anticancer原始数据评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Cancer Type One-letter amino-acid sequence               class\n",
      "1654    Lung Cancer     SEEEENNVIEQAKEEIKEAIKKADET  inactive - virtual\n",
      "1198    Lung Cancer           DPKRLQASLQTIVGMVVYSW  inactive - virtual\n",
      "115   Breast Cancer               GLFKVIKKVASVIGGL         mod. active\n",
      "851   Breast Cancer                 TEQDIIDLKFAIAD  inactive - virtual\n",
      "844   Breast Cancer                 TDAEAKQLAQWILS  inactive - virtual\n",
      "Logistic Regression Accuracy: 0.775\n",
      "Decision Tree Accuracy: 0.835\n",
      "Random Forest Accuracy: 0.825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/guoquanjiang/envs/begreat/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/Data/Health & Medicine/anticancer peptides.csv')\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "data=data.sample(n=1000)\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class']\n",
    "# Encode categorical features with Label Encoding\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode target column if it is categorical\n",
    "if y.dtype == 'object':\n",
    "    target_le = LabelEncoder()\n",
    "    y = target_le.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=100)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy}')\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(max_depth=600)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(max_depth=12, n_estimators=75)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##estimation_obesity合成数据评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Gender   Age    Height      Weight family_history_with_overweight FAVC  \\\n",
      "0  Female  19.0  1.680000   80.000000                            yes  yes   \n",
      "1    Male  23.0  1.893732  129.754763                            yes  yes   \n",
      "2  Female  25.0  1.870000   75.000000                            yes  yes   \n",
      "3  Female  32.0  1.600000  133.000000                            yes  yes   \n",
      "4  Female  21.0  1.600000   58.000000                            yes  yes   \n",
      "\n",
      "       FCVC       NCP       CAEC SMOKE  CH2O SCC  FAF       TUE        CALC  \\\n",
      "0  2.000000  3.000000  Sometimes    no   2.0  no  0.0  0.000000  Frequently   \n",
      "1  2.336486  1.848168  Sometimes    no   2.0  no  0.0  1.880194          no   \n",
      "2  2.000000  3.000000  Sometimes    no   2.0  no  1.0  1.000000   Sometimes   \n",
      "3  2.000000  3.000000  Sometimes    no   2.0  no  0.0  0.000000   Sometimes   \n",
      "4  2.000000  2.000000  Sometimes   yes   3.0  no  1.0  0.000000  Frequently   \n",
      "\n",
      "                  MTRANS          NObeyesdad  \n",
      "0  Public_Transportation  Overweight_Level_I  \n",
      "1  Public_Transportation     Obesity_Type_II  \n",
      "2  Public_Transportation  Overweight_Level_I  \n",
      "3  Public_Transportation     Obesity_Type_II  \n",
      "4  Public_Transportation       Normal_Weight  \n",
      "Logistic Regression Accuracy: 0.34\n",
      "Decision Tree Accuracy: 0.305\n",
      "Random Forest Accuracy: 0.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/guoquanjiang/envs/begreat/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/sample_data/Health & Medicine/obesity_samples.csv')\n",
    "# data = pd.read_csv('/data/guoquanjiang/be_great/sample_data/california_samples.csv')\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('NObeyesdad', axis=1)\n",
    "y = data['NObeyesdad']\n",
    "# Encode categorical features with Label Encoding\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode target column if it is categorical\n",
    "if y.dtype == 'object':\n",
    "    target_le = LabelEncoder()\n",
    "    y = target_le.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=100)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy}')\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(max_depth=10)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(max_depth=12, n_estimators=75)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##estimation_obesity原始数据评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Gender        Age    Height      Weight family_history_with_overweight  \\\n",
      "566     Male  19.329542  1.767335   55.700497                            yes   \n",
      "1237    Male  35.389491  1.780000  100.847630                            yes   \n",
      "1760    Male  31.490699  1.773521  120.209711                            yes   \n",
      "1362  Female  18.107092  1.703259   91.499683                            yes   \n",
      "1909  Female  21.501721  1.809871  152.394739                            yes   \n",
      "\n",
      "     FAVC      FCVC       NCP       CAEC SMOKE      CH2O SCC       FAF  \\\n",
      "566   yes  2.000000  4.000000  Sometimes    no  2.157395  no  2.000000   \n",
      "1237  yes  2.069267  1.476204  Sometimes    no  3.000000  no  2.052520   \n",
      "1760  yes  2.777165  3.000000  Sometimes    no  2.106861  no  0.925941   \n",
      "1362  yes  1.899793  3.000000  Sometimes    no  1.439962  no  0.952900   \n",
      "1909  yes  3.000000  3.000000  Sometimes    no  2.351207  no  0.246831   \n",
      "\n",
      "           TUE        CALC                 MTRANS           NObeyesdad  \n",
      "566   1.679149          no             Automobile  Insufficient_Weight  \n",
      "1237  0.092736  Frequently             Automobile       Obesity_Type_I  \n",
      "1760  0.291600   Sometimes             Automobile      Obesity_Type_II  \n",
      "1362  0.838847   Sometimes  Public_Transportation       Obesity_Type_I  \n",
      "1909  0.913360   Sometimes  Public_Transportation     Obesity_Type_III  \n",
      "Logistic Regression Accuracy: 0.625\n",
      "Decision Tree Accuracy: 0.89\n",
      "Random Forest Accuracy: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/guoquanjiang/envs/begreat/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/Data/Health & Medicine/Estimation of Obesity Levels Based On Eating Habits and Physical Condition.csv')\n",
    "# data = pd.read_csv('/data/guoquanjiang/be_great/sample_data/california_samples.csv')\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "data=data.sample(n=1000)\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('NObeyesdad', axis=1)\n",
    "y = data['NObeyesdad']\n",
    "# Encode categorical features with Label Encoding\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode target column if it is categorical\n",
    "if y.dtype == 'object':\n",
    "    target_le = LabelEncoder()\n",
    "    y = target_le.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=100)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy}')\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(max_depth=10)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(max_depth=12, n_estimators=75)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##maternal_health合成数据评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age  Systolic Blood Pressure  Diastolic Blood Pressure  Blood glucose  \\\n",
      "0  19.0                    100.0                      60.0            7.5   \n",
      "1  55.0                    120.0                      80.0            6.9   \n",
      "2  12.0                    140.0                      95.0            9.0   \n",
      "3  19.0                    110.0                      60.0            7.5   \n",
      "4  29.0                    120.0                      80.0            7.0   \n",
      "\n",
      "   BodyTemp  HeartRate  RiskLevel  \n",
      "0      98.0       77.0   low risk  \n",
      "1      98.0       76.0   low risk  \n",
      "2      98.0       70.0  high risk  \n",
      "3      98.0       70.0   mid risk  \n",
      "4      98.0       88.0   mid risk  \n",
      "Logistic Regression Accuracy: 0.535\n",
      "Decision Tree Accuracy: 0.495\n",
      "Random Forest Accuracy: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/guoquanjiang/envs/begreat/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/sample_data/Health & Medicine/maternal_samples.csv')\n",
    "# data = pd.read_csv('/data/guoquanjiang/be_great/sample_data/california_samples.csv')\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('RiskLevel', axis=1)\n",
    "y = data['RiskLevel']\n",
    "# Encode categorical features with Label Encoding\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode target column if it is categorical\n",
    "if y.dtype == 'object':\n",
    "    target_le = LabelEncoder()\n",
    "    y = target_le.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=100)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy}')\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(max_depth=10)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(max_depth=12, n_estimators=75)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##maternal_health原始数据评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Age  Systolic Blood Pressure  Diastolic Blood Pressure  Blood glucose  \\\n",
      "25     16                      100                        70            7.2   \n",
      "111    38                      135                        60            7.9   \n",
      "671    15                      100                        49            6.8   \n",
      "1010   55                      120                        90           18.0   \n",
      "498    15                       76                        49            7.9   \n",
      "\n",
      "      BodyTemp  HeartRate  RiskLevel  \n",
      "25        98.0         80   low risk  \n",
      "111      101.0         86  high risk  \n",
      "671       99.0         77   low risk  \n",
      "1010      98.0         60  high risk  \n",
      "498       98.0         77   low risk  \n",
      "Logistic Regression Accuracy: 0.66\n",
      "Decision Tree Accuracy: 0.775\n",
      "Random Forest Accuracy: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/guoquanjiang/envs/begreat/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/Data/Health & Medicine/Maternal Health Risk Data Set.csv')\n",
    "# data = pd.read_csv('/data/guoquanjiang/be_great/sample_data/california_samples.csv')\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "data=data.sample(n=1000)\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('RiskLevel', axis=1)\n",
    "y = data['RiskLevel']\n",
    "# Encode categorical features with Label Encoding\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode target column if it is categorical\n",
    "if y.dtype == 'object':\n",
    "    target_le = LabelEncoder()\n",
    "    y = target_le.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=100)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy}')\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(max_depth=10)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(max_depth=12, n_estimators=75)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
