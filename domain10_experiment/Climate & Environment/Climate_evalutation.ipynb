{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Beijing_PM2.5合成数据评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     year  month   day  hour  PM2.5 concentration (ug/m^3)  Dew Point  \\\n",
      "1  2013.0    4.0   6.0  13.0                          64.0      -19.0   \n",
      "2  2014.0   12.0   7.0  17.0                          17.0      -16.0   \n",
      "3  2012.0   11.0  10.0   7.0                          42.0       12.0   \n",
      "4  2010.0   10.0  13.0  13.0                          34.0        0.0   \n",
      "5  2013.0   10.0  23.0   7.0                          24.0      -20.0   \n",
      "\n",
      "   Temperature  Pressure (hPa) Combined wind direction  \\\n",
      "1         -5.0          1021.0                      NW   \n",
      "2         12.0          1018.0                      NE   \n",
      "3         22.0          1013.0                      SE   \n",
      "4         15.0          1014.0                      NW   \n",
      "5         17.0          1023.0                      SE   \n",
      "\n",
      "   Cumulated wind speed (m/s)  Cumulated hours of snow  \\\n",
      "1                       55.13                      0.0   \n",
      "2                        0.99                      0.0   \n",
      "3                        1.78                      0.0   \n",
      "4                        1.79                      0.0   \n",
      "5                        0.89                      0.0   \n",
      "\n",
      "   Cumulated hours of rain  \n",
      "1                      0.0  \n",
      "2                      0.0  \n",
      "3                      0.0  \n",
      "4                      0.0  \n",
      "5                      0.0  \n",
      "Linear Regression Mean Squared Error: 11450.907433233368\n",
      "Decision Tree Regressor Mean Squared Error: 15343.170696376705\n",
      "Random Forest Regressor Mean Squared Error: 11372.312563329831\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Assuming the data is provided in the format given in the prompt\n",
    "data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/sample_data/Climate & Environment/beijing_samples.csv')\n",
    "data=data.dropna()\n",
    "# data = datasets.fetch_california_housing(as_frame=True).frame\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('PM2.5 concentration (ug/m^3)', axis=1)\n",
    "y = data['PM2.5 concentration (ug/m^3)']\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode target column if it is categorical\n",
    "if y.dtype == 'object':\n",
    "    target_le = LabelEncoder()\n",
    "    y = target_le.fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
    "print(f'Linear Regression Mean Squared Error: {lr_mse}')\n",
    "\n",
    "# Decision Tree Regressor\n",
    "dt_model = DecisionTreeRegressor(max_depth=10)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_mse = mean_squared_error(y_test, dt_predictions)\n",
    "print(f'Decision Tree Regressor Mean Squared Error: {dt_mse}')\n",
    "\n",
    "# Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(max_depth=12, n_estimators=85)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_mse = mean_squared_error(y_test, rf_predictions)\n",
    "print(f'Random Forest Regressor Mean Squared Error: {rf_mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beijing_PM2.5原始数据评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       year  month  day  hour  PM2.5 concentration (ug/m^3)  Dew Point  \\\n",
      "859    2010      2    5    19                          63.0        -13   \n",
      "29839  2013      5   28     7                          99.0         17   \n",
      "37002  2014      3   22    18                          11.0        -21   \n",
      "29222  2013      5    2    14                          98.0          1   \n",
      "38168  2014      5   10     8                          47.0          6   \n",
      "\n",
      "       Temperature  Pressure (hPa) Combined wind direction  \\\n",
      "859           -4.0          1031.0                      SE   \n",
      "29839         19.0          1005.0                      NW   \n",
      "37002         21.0          1018.0                      NE   \n",
      "29222         24.0          1011.0                      SE   \n",
      "38168         16.0          1017.0                      SE   \n",
      "\n",
      "       Cumulated wind speed (m/s)  Cumulated hours of snow  \\\n",
      "859                          8.05                        0   \n",
      "29839                        1.79                        0   \n",
      "37002                       27.27                        0   \n",
      "29222                       12.07                        0   \n",
      "38168                        1.79                        0   \n",
      "\n",
      "       Cumulated hours of rain  \n",
      "859                          0  \n",
      "29839                        2  \n",
      "37002                        0  \n",
      "29222                        0  \n",
      "38168                        0  \n",
      "Linear Regression Mean Squared Error: 6682.719176542975\n",
      "Decision Tree Regressor Mean Squared Error: 8607.779046674847\n",
      "Random Forest Regressor Mean Squared Error: 4625.228320358009\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Assuming the data is provided in the format given in the prompt\n",
    "data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/Data/Climate & Environment/beijing+pm2.5+data.csv')\n",
    "data=data.sample(n=1000)\n",
    "data=data.dropna()\n",
    "# data = datasets.fetch_california_housing(as_frame=True).frame\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('PM2.5 concentration (ug/m^3)', axis=1)\n",
    "y = data['PM2.5 concentration (ug/m^3)']\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode target column if it is categorical\n",
    "if y.dtype == 'object':\n",
    "    target_le = LabelEncoder()\n",
    "    y = target_le.fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
    "print(f'Linear Regression Mean Squared Error: {lr_mse}')\n",
    "\n",
    "# Decision Tree Regressor\n",
    "dt_model = DecisionTreeRegressor(max_depth=10)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_mse = mean_squared_error(y_test, dt_predictions)\n",
    "print(f'Decision Tree Regressor Mean Squared Error: {dt_mse}')\n",
    "\n",
    "# Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(max_depth=12, n_estimators=85)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_mse = mean_squared_error(y_test, rf_predictions)\n",
    "print(f'Random Forest Regressor Mean Squared Error: {rf_mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Rain_in_Australia合成数据评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date  Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
      "0   2011-03-23   Woomera     21.7     32.7       0.0          1.8       3.5   \n",
      "5   2011-12-09  Richmond     21.1     22.9       0.0          7.7      10.9   \n",
      "6   2009-09-17    Albury      9.3     16.7       6.6          4.3       5.4   \n",
      "12  2013-02-18  Richmond     12.3     28.0       0.0          3.4       8.5   \n",
      "16  2009-01-27  Richmond     14.3     26.9       0.0          4.2       4.4   \n",
      "\n",
      "   WindGustDir  WindGustSpeed WindDir9am  ... Humidity9am  Humidity3pm  \\\n",
      "0            W           72.0        ENE  ...        70.0         60.0   \n",
      "5          NNW           50.0        NNE  ...        70.0         55.0   \n",
      "6          WNW           48.0          W  ...        63.0         33.0   \n",
      "12          NW           26.0        WNW  ...        46.0         44.0   \n",
      "16           W           31.0         SE  ...        65.0         70.0   \n",
      "\n",
      "    Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n",
      "0        1022.7       1021.9       1.0       1.0     23.1     28.3         No   \n",
      "5        1013.8       1014.9       8.0       8.0     22.8     24.3         No   \n",
      "6        1010.5       1019.8       7.0       5.0     13.0     14.4         No   \n",
      "12       1020.7       1020.9       1.0       1.0     22.8     25.0         No   \n",
      "16       1018.0       1012.5       6.0       4.0     16.1     24.8         No   \n",
      "\n",
      "    RainTomorrow  \n",
      "0             No  \n",
      "5             No  \n",
      "6             No  \n",
      "12            No  \n",
      "16            No  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "Logistic Regression Accuracy: 0.7272727272727273\n",
      "Decision Tree Accuracy: 0.696969696969697\n",
      "Random Forest Accuracy: 0.7878787878787878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/guoquanjiang/envs/begreat/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/sample_data/Climate & Environment/australia_samples.csv')\n",
    "data=data.dropna()\n",
    "# data = pd.read_csv('/data/guoquanjiang/be_great/sample_data/california_samples.csv')\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('RainTomorrow', axis=1)\n",
    "y = data['RainTomorrow']\n",
    "# Encode categorical features with Label Encoding\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode target column if it is categorical\n",
    "if y.dtype == 'object':\n",
    "    target_le = LabelEncoder()\n",
    "    y = target_le.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=100)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy}')\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(max_depth=10)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(max_depth=12, n_estimators=75)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Rain_in_Australia原始数据评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Date       Location  MinTemp  MaxTemp  Rainfall  Evaporation  \\\n",
      "89498   2015-06-15         Cairns     21.4     27.0       6.8          2.0   \n",
      "69035   2013-10-07      Melbourne      9.3     17.9       3.0          3.4   \n",
      "34450   2011-08-19  SydneyAirport      8.2     17.2       0.6          4.2   \n",
      "121013  2009-07-11          Perth      7.9     17.4       4.0          1.8   \n",
      "6187    2009-05-19          Cobar     12.8     14.7       7.6          4.6   \n",
      "\n",
      "        Sunshine WindGustDir  WindGustSpeed WindDir9am  ... Humidity9am  \\\n",
      "89498        5.8         ESE           56.0        SSE  ...        85.0   \n",
      "69035        7.5         SSW           28.0        WSW  ...        73.0   \n",
      "34450        0.7          SE           81.0          W  ...        89.0   \n",
      "121013       7.3         WSW           22.0        NNE  ...        85.0   \n",
      "6187         0.0          NE           41.0        ENE  ...        96.0   \n",
      "\n",
      "        Humidity3pm  Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  \\\n",
      "89498          68.0       1016.8       1014.3       7.0       5.0     24.2   \n",
      "69035          38.0       1015.0       1013.5       7.0       2.0     11.0   \n",
      "34450          76.0       1014.1       1016.1       7.0       8.0      9.4   \n",
      "121013         50.0       1014.3       1013.5       3.0       2.0     11.0   \n",
      "6187           91.0       1018.7       1015.6       8.0       8.0     13.9   \n",
      "\n",
      "        Temp3pm  RainToday  RainTomorrow  \n",
      "89498      26.6        Yes           Yes  \n",
      "69035      17.5        Yes            No  \n",
      "34450      16.0         No           Yes  \n",
      "121013     17.1        Yes            No  \n",
      "6187       13.7        Yes           Yes  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "Logistic Regression Accuracy: 0.8157894736842105\n",
      "Decision Tree Accuracy: 0.7105263157894737\n",
      "Random Forest Accuracy: 0.8421052631578947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/guoquanjiang/envs/begreat/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/Data/Climate & Environment/Rain in Australia.csv')\n",
    "# data = pd.read_csv('/data/guoquanjiang/be_great/sample_data/california_samples.csv')\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "data=data.sample(n=1000)\n",
    "data=data.dropna()\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('RainTomorrow', axis=1)\n",
    "y = data['RainTomorrow']\n",
    "# Encode categorical features with Label Encoding\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode target column if it is categorical\n",
    "if y.dtype == 'object':\n",
    "    target_le = LabelEncoder()\n",
    "    y = target_le.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=100)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy}')\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(max_depth=10)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(max_depth=12, n_estimators=75)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forest_fire合成数据评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x-axis spatial coordinate  y-axis spatial coordinate month  day  \\\n",
      "0                        1.0                        4.0   sep  mon   \n",
      "1                        1.0                        7.0   jul  thu   \n",
      "2                        5.0                        3.0   sep  sat   \n",
      "3                        1.0                        2.0   aug  mon   \n",
      "4                        5.0                        5.0   aug  sun   \n",
      "\n",
      "   FFMC index  DMC index  DC index  ISI index  temperature  relative humidity  \\\n",
      "0        84.7       91.9      48.6        7.0         28.6               35.0   \n",
      "1        91.9      137.1     692.0        8.8         13.1               43.0   \n",
      "2        99.4      124.3     706.0        7.9         21.3               39.0   \n",
      "3        92.7      124.2     545.7        7.1         21.8               56.0   \n",
      "4        92.7       99.0     674.1        7.7         23.8               48.0   \n",
      "\n",
      "   wind speed  outside rain  the burned area of the forest  \n",
      "0         3.2           0.0                           2.55  \n",
      "1         3.7           0.0                          11.24  \n",
      "2         4.1           0.0                          13.70  \n",
      "3         3.4           0.0                          11.06  \n",
      "4         2.3           0.0                           0.00  \n",
      "Linear Regression Mean Squared Error: 6826.929926764879\n",
      "Decision Tree Regressor Mean Squared Error: 7039.910084662487\n",
      "Random Forest Regressor Mean Squared Error: 7023.5661294828615\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Assuming the data is provided in the format given in the prompt\n",
    "data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/sample_data/Climate & Environment/forest_samples.csv')\n",
    "\n",
    "# data = datasets.fetch_california_housing(as_frame=True).frame\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('the burned area of the forest', axis=1)\n",
    "y = data['the burned area of the forest']\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode target column if it is categorical\n",
    "if y.dtype == 'object':\n",
    "    target_le = LabelEncoder()\n",
    "    y = target_le.fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
    "print(f'Linear Regression Mean Squared Error: {lr_mse}')\n",
    "\n",
    "# Decision Tree Regressor\n",
    "dt_model = DecisionTreeRegressor(max_depth=10)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_mse = mean_squared_error(y_test, dt_predictions)\n",
    "print(f'Decision Tree Regressor Mean Squared Error: {dt_mse}')\n",
    "\n",
    "# Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(max_depth=12, n_estimators=85)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_mse = mean_squared_error(y_test, rf_predictions)\n",
    "print(f'Random Forest Regressor Mean Squared Error: {rf_mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forest_fire原始数据评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x-axis spatial coordinate  y-axis spatial coordinate month  day  \\\n",
      "0                          7                          5   mar  fri   \n",
      "1                          7                          4   oct  tue   \n",
      "2                          7                          4   oct  sat   \n",
      "3                          8                          6   mar  fri   \n",
      "4                          8                          6   mar  sun   \n",
      "\n",
      "   FFMC index  DMC index  DC index  ISI index  temperature  relative humidity  \\\n",
      "0        86.2       26.2      94.3        5.1          8.2                 51   \n",
      "1        90.6       35.4     669.1        6.7         18.0                 33   \n",
      "2        90.6       43.7     686.9        6.7         14.6                 33   \n",
      "3        91.7       33.3      77.5        9.0          8.3                 97   \n",
      "4        89.3       51.3     102.2        9.6         11.4                 99   \n",
      "\n",
      "   wind speed  outside rain  the burned area of the forest  \n",
      "0         6.7           0.0                            0.0  \n",
      "1         0.9           0.0                            0.0  \n",
      "2         1.3           0.0                            0.0  \n",
      "3         4.0           0.2                            0.0  \n",
      "4         1.8           0.0                            0.0  \n",
      "Linear Regression Mean Squared Error: 11748.943154648765\n",
      "Decision Tree Regressor Mean Squared Error: 9376.839936344635\n",
      "Random Forest Regressor Mean Squared Error: 11744.353183819174\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Assuming the data is provided in the format given in the prompt\n",
    "data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/Data/Climate & Environment/forest+fires.csv')\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('the burned area of the forest', axis=1)\n",
    "y = data['the burned area of the forest']\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode target column if it is categorical\n",
    "if y.dtype == 'object':\n",
    "    target_le = LabelEncoder()\n",
    "    y = target_le.fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
    "print(f'Linear Regression Mean Squared Error: {lr_mse}')\n",
    "\n",
    "# Decision Tree Regressor\n",
    "dt_model = DecisionTreeRegressor(max_depth=10)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_mse = mean_squared_error(y_test, dt_predictions)\n",
    "print(f'Decision Tree Regressor Mean Squared Error: {dt_mse}')\n",
    "\n",
    "# Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(max_depth=12, n_estimators=85)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_mse = mean_squared_error(y_test, rf_predictions)\n",
    "print(f'Random Forest Regressor Mean Squared Error: {rf_mse}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
