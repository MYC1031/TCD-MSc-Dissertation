{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##accelerometer合成数据评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       wconfid  Cooler Fan RPM Speed Percentage ID  \\\n",
      "0       opposite configuration                                65.0   \n",
      "1  perpendicular configuration                                75.0   \n",
      "2         normal configuration                                85.0   \n",
      "3  perpendicular configuration                                40.0   \n",
      "4         normal configuration                                45.0   \n",
      "\n",
      "   Accelerometer x value  Accelerometer y value  Accelerometer z value  \n",
      "0                  0.977                  0.047                  0.008  \n",
      "1                  0.977                 -0.137                 -0.133  \n",
      "2                  1.020                 -0.020                 -0.355  \n",
      "3                  1.016                 -0.004                 -0.117  \n",
      "4                  0.902                  0.066                 -0.484  \n",
      "Logistic Regression Accuracy: 0.355\n",
      "Decision Tree Accuracy: 0.395\n",
      "Random Forest Accuracy: 0.35\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/sample_data/Physics & Chemistry/accelerometer_samples.csv')\n",
    "# data = pd.read_csv('/data/guoquanjiang/be_great/sample_data/california_samples.csv')\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('wconfid', axis=1)\n",
    "y = data['wconfid']\n",
    "# Encode categorical features with Label Encoding\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode target column if it is categorical\n",
    "if y.dtype == 'object':\n",
    "    target_le = LabelEncoder()\n",
    "    y = target_le.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=100)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy}')\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(max_depth=10)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(max_depth=12, n_estimators=75)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accelerometer原始数据评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           wconfid  Cooler Fan RPM Speed Percentage ID  \\\n",
      "89369  perpendicular configuration                                  80   \n",
      "71115  perpendicular configuration                                  50   \n",
      "70431  perpendicular configuration                                  50   \n",
      "88542  perpendicular configuration                                  80   \n",
      "79043  perpendicular configuration                                  65   \n",
      "\n",
      "       Accelerometer x value  Accelerometer y value  Accelerometer z value  \n",
      "89369                  0.887                 -0.289                 -0.148  \n",
      "71115                  1.098                 -0.184                  0.031  \n",
      "70431                  1.023                  0.043                 -0.074  \n",
      "88542                  1.070                  0.664                  0.172  \n",
      "79043                  1.129                 -0.137                  0.215  \n",
      "Logistic Regression Accuracy: 0.31\n",
      "Decision Tree Accuracy: 0.615\n",
      "Random Forest Accuracy: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/guoquanjiang/envs/begreat/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/Data/Physics & Chemistry/accelerometer.csv')\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "data=data.sample(n=1000)\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('wconfid', axis=1)\n",
    "y = data['wconfid']\n",
    "# Encode categorical features with Label Encoding\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode target column if it is categorical\n",
    "if y.dtype == 'object':\n",
    "    target_le = LabelEncoder()\n",
    "    y = target_le.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=100)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy}')\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(max_depth=600)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(max_depth=12, n_estimators=75)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##steel_industry合成数据评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               date  Usage_kWh  Lagging_Current_Reactive.Power_kVarh  \\\n",
      "0  05/06/2018 02:30      62.77                                 69.72   \n",
      "1  29/04/2018 09:00       2.46                                  5.16   \n",
      "2  07/06/2018 00:00       3.95                                 44.81   \n",
      "3  04/10/2018 12:30      46.30                                  0.00   \n",
      "4  13/11/2018 19:00       3.77                                  4.82   \n",
      "\n",
      "   Leading_Current_Reactive_Power_kVarh  CO2(tCO2)  \\\n",
      "0                                  0.00       0.00   \n",
      "1                                  0.00       0.00   \n",
      "2                                  0.00       0.00   \n",
      "3                                 18.02       0.02   \n",
      "4                                  0.00       0.03   \n",
      "\n",
      "   Lagging_Current_Power_Factor  Leading_Current_Power_Factor      NSM  \\\n",
      "0                         99.79                         99.96  15300.0   \n",
      "1                         54.01                        100.00  33300.0   \n",
      "2                        100.00                        100.00  81900.0   \n",
      "3                         88.18                        100.00  52200.0   \n",
      "4                        100.00                         30.29  53700.0   \n",
      "\n",
      "  WeekStatus Day_of_week    Load_Type  \n",
      "0    Weekend      Sunday   Light_Load  \n",
      "1    Weekday    Thursday   Light_Load  \n",
      "2    Weekday    Thursday   Light_Load  \n",
      "3    Weekend      Sunday  Medium_Load  \n",
      "4    Weekday    Thursday  Medium_Load  \n",
      "Logistic Regression Accuracy: 0.56\n",
      "Decision Tree Accuracy: 0.445\n",
      "Random Forest Accuracy: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/guoquanjiang/envs/begreat/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/sample_data/Physics & Chemistry/steel_industry_samples.csv')\n",
    "# data = pd.read_csv('/data/guoquanjiang/be_great/sample_data/california_samples.csv')\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('Load_Type', axis=1)\n",
    "y = data['Load_Type']\n",
    "# Encode categorical features with Label Encoding\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode target column if it is categorical\n",
    "if y.dtype == 'object':\n",
    "    target_le = LabelEncoder()\n",
    "    y = target_le.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=100)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy}')\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(max_depth=10)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(max_depth=12, n_estimators=75)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##steel_industry原始数据评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   date  Usage_kWh  Lagging_Current_Reactive.Power_kVarh  \\\n",
      "21278  10/08/2018 15:45     131.00                                 62.42   \n",
      "13661  23/05/2018 07:30       3.67                                  5.00   \n",
      "9045   05/04/2018 05:30       3.67                                  5.08   \n",
      "15879  15/06/2018 10:00      53.75                                 35.68   \n",
      "6461   09/03/2018 07:30       6.34                                  3.64   \n",
      "\n",
      "       Leading_Current_Reactive_Power_kVarh  CO2(tCO2)  \\\n",
      "21278                                   0.0       0.06   \n",
      "13661                                   0.0       0.00   \n",
      "9045                                    0.0       0.00   \n",
      "15879                                   0.0       0.02   \n",
      "6461                                    0.0       0.00   \n",
      "\n",
      "       Lagging_Current_Power_Factor  Leading_Current_Power_Factor    NSM  \\\n",
      "21278                         90.28                         100.0  56700   \n",
      "13661                         59.17                         100.0  27000   \n",
      "9045                          58.56                         100.0  19800   \n",
      "15879                         83.31                         100.0  36000   \n",
      "6461                          86.72                         100.0  27000   \n",
      "\n",
      "      WeekStatus Day_of_week     Load_Type  \n",
      "21278    Weekday      Friday  Maximum_Load  \n",
      "13661    Weekday   Wednesday    Light_Load  \n",
      "9045     Weekday    Thursday    Light_Load  \n",
      "15879    Weekday      Friday   Medium_Load  \n",
      "6461     Weekday      Friday    Light_Load  \n",
      "Logistic Regression Accuracy: 0.645\n",
      "Decision Tree Accuracy: 0.88\n",
      "Random Forest Accuracy: 0.895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/guoquanjiang/envs/begreat/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/Data/Physics & Chemistry/Steel_industry_data.csv')\n",
    "# data = pd.read_csv('/data/guoquanjiang/be_great/sample_data/california_samples.csv')\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "data=data.sample(n=1000)\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('Load_Type', axis=1)\n",
    "y = data['Load_Type']\n",
    "# Encode categorical features with Label Encoding\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode target column if it is categorical\n",
    "if y.dtype == 'object':\n",
    "    target_le = LabelEncoder()\n",
    "    y = target_le.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=100)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy}')\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(max_depth=10)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(max_depth=12, n_estimators=75)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##concrete合成数据评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Cement  Blast Furnace Slag  Fly Ash   Water  Superplasticizer  \\\n",
      "0  380.00                 0.0     0.00  228.00              0.00   \n",
      "1  173.08                 0.0   118.34  159.59              8.33   \n",
      "2  427.00                 0.0     0.00  187.00              0.00   \n",
      "3  236.00                 0.0    97.50  196.00             12.80   \n",
      "4  213.00                 0.0     0.00  200.00              7.00   \n",
      "\n",
      "   Coarse Aggregate  Fine Aggregate    Age  Concrete compressive strength   \n",
      "0             968.0          801.00   28.0                        33.48883  \n",
      "1            1057.8          856.91   28.0                        36.56291  \n",
      "2             932.0          794.00   28.0                        10.53519  \n",
      "3             932.0          875.00  100.0                        52.90832  \n",
      "4             966.0          801.00    7.0                        43.73346  \n",
      "Linear Regression Mean Squared Error: 290.2247188836884\n",
      "Decision Tree Regressor Mean Squared Error: 459.62947573854706\n",
      "Random Forest Regressor Mean Squared Error: 313.3570187001799\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Assuming the data is provided in the format given in the prompt\n",
    "data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/sample_data/Physics & Chemistry/concrete_samples.csv')\n",
    "\n",
    "# data = datasets.fetch_california_housing(as_frame=True).frame\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('Concrete compressive strength ', axis=1)\n",
    "y = data['Concrete compressive strength ']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
    "print(f'Linear Regression Mean Squared Error: {lr_mse}')\n",
    "\n",
    "# Decision Tree Regressor\n",
    "dt_model = DecisionTreeRegressor(max_depth=10)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_mse = mean_squared_error(y_test, dt_predictions)\n",
    "print(f'Decision Tree Regressor Mean Squared Error: {dt_mse}')\n",
    "\n",
    "# Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(max_depth=12, n_estimators=85)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_mse = mean_squared_error(y_test, rf_predictions)\n",
    "print(f'Random Forest Regressor Mean Squared Error: {rf_mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##concrete原始数据评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
      "148   380.0                 0.0      0.0  192.0               0.0   \n",
      "972   446.0                 0.0      0.0  192.0               0.0   \n",
      "822   425.0                 0.0      0.0  195.0               0.0   \n",
      "729   212.8                 0.0      0.0  175.3               0.0   \n",
      "712   374.0                 0.0      0.0  192.0               0.0   \n",
      "\n",
      "     Coarse Aggregate  Fine Aggregate   Age  Concrete compressive strength   \n",
      "148            1040.0           613.0  28.0                        25.68988  \n",
      "972             936.0           881.0  28.0                        12.17615  \n",
      "822            1032.0           874.0  28.0                        66.69991  \n",
      "729             943.2           744.8  56.0                        55.94408  \n",
      "712            1065.0           805.0  28.0                        36.43881  \n",
      "Linear Regression Mean Squared Error: 288.52029978421706\n",
      "Decision Tree Regressor Mean Squared Error: 462.73590852890015\n",
      "Random Forest Regressor Mean Squared Error: 315.8637233845356\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Assuming the data is provided in the format given in the prompt\n",
    "data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/sample_data/Physics & Chemistry/concrete_samples.csv')\n",
    "data=data.sample(n=1000)\n",
    "# data = datasets.fetch_california_housing(as_frame=True).frame\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('Concrete compressive strength ', axis=1)\n",
    "y = data['Concrete compressive strength ']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
    "print(f'Linear Regression Mean Squared Error: {lr_mse}')\n",
    "\n",
    "# Decision Tree Regressor\n",
    "dt_model = DecisionTreeRegressor(max_depth=10)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_mse = mean_squared_error(y_test, dt_predictions)\n",
    "print(f'Decision Tree Regressor Mean Squared Error: {dt_mse}')\n",
    "\n",
    "# Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(max_depth=12, n_estimators=85)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_mse = mean_squared_error(y_test, rf_predictions)\n",
    "print(f'Random Forest Regressor Mean Squared Error: {rf_mse}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
