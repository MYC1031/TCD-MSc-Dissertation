{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT2+LORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                1.2               5.3                2.1               0.9   \n",
      "1                5.5               0.1                1.5               2.7   \n",
      "2                5.8               0.1                5.6               3.1   \n",
      "3                6.1               0.1                7.0               0.2   \n",
      "4                1.0               3.5                5.2               0.4   \n",
      "\n",
      "   target  \n",
      "0     2.0  \n",
      "1     0.0  \n",
      "2     2.0  \n",
      "3     0.0  \n",
      "4     1.0  \n",
      "Logistic Regression Accuracy: 0.4666666666666667\n",
      "Decision Tree Accuracy: 0.3333333333333333\n",
      "Random Forest Accuracy: 0.23333333333333334\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/sample_data/model_finetune/gpt2_lora.csv')\n",
    "# data['target'] = data['target'].apply(lambda x: x if x in [1.0, 2.0] else 0)\n",
    "# data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/sample_data/california_samples.csv')\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "# X = data.drop('Class', axis=1)\n",
    "# y = data['Class']\n",
    "# Encode categorical features with Label Encoding\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode target column if it is categorical\n",
    "if y.dtype == 'object':\n",
    "    target_le = LabelEncoder()\n",
    "    y = target_le.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=100)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy}')\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(max_depth=600)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(max_depth=12, n_estimators=75)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT2+QLORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                1.2               5.3                2.1               0.9   \n",
      "1                5.5               0.1                6.2               3.0   \n",
      "2                5.2               0.2                2.0               2.0   \n",
      "3                6.1               0.7                1.3               0.2   \n",
      "4                1.0               0.5                5.2               0.4   \n",
      "\n",
      "   target  \n",
      "0     2.0  \n",
      "1     0.0  \n",
      "2     2.0  \n",
      "3     0.0  \n",
      "4     1.0  \n",
      "Logistic Regression Accuracy: 0.4\n",
      "Decision Tree Accuracy: 0.4\n",
      "Random Forest Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/sample_data/model_finetune/gpt2_qlora.csv')\n",
    "# data['target'] = data['target'].apply(lambda x: x if x in [1.0, 2.0] else 0)\n",
    "# data = pd.read_csv('/data/guoquanjiang/be_great/sample_data/california_samples.csv')\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "# X = data.drop('Class', axis=1)\n",
    "# y = data['Class']\n",
    "# Encode categorical features with Label Encoding\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode target column if it is categorical\n",
    "if y.dtype == 'object':\n",
    "    target_le = LabelEncoder()\n",
    "    y = target_le.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=100)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy}')\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(max_depth=600)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(max_depth=12, n_estimators=75)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT2+DORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                6.4               3.1                5.6               2.4   \n",
      "1                5.2               3.5                1.5               0.2   \n",
      "2                5.1               3.8                1.6               0.2   \n",
      "3                6.3               2.9                5.6               2.3   \n",
      "4                6.0               2.9                4.5               1.5   \n",
      "\n",
      "   target  \n",
      "0     2.0  \n",
      "1     1.0  \n",
      "2     1.0  \n",
      "3     2.0  \n",
      "4     1.0  \n",
      "Logistic Regression Accuracy: 0.8333333333333334\n",
      "Decision Tree Accuracy: 0.9\n",
      "Random Forest Accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/sample_data/model_finetune/llama2_7B_dora.csv')\n",
    "data['target'] = data['target'].apply(lambda x: x if x in [1.0, 2.0] else 0)\n",
    "# data = pd.read_csv('/data/guoquanjiang/be_great/sample_data/california_samples.csv')\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "# X = data.drop('Class', axis=1)\n",
    "# y = data['Class']\n",
    "# Encode categorical features with Label Encoding\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode target column if it is categorical\n",
    "if y.dtype == 'object':\n",
    "    target_le = LabelEncoder()\n",
    "    y = target_le.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=100)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy}')\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(max_depth=600)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(max_depth=12, n_estimators=75)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGLM+LORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/sample_data/model_finetune/llama2_7B_dora.csv')\n",
    "data['target'] = data['target'].apply(lambda x: x if x in [1.0, 2.0] else 0)\n",
    "# data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/sample_data/california_samples.csv')\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "# X = data.drop('Class', axis=1)\n",
    "# y = data['Class']\n",
    "# Encode categorical features with Label Encoding\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode target column if it is categorical\n",
    "if y.dtype == 'object':\n",
    "    target_le = LabelEncoder()\n",
    "    y = target_le.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=100)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy}')\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(max_depth=600)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(max_depth=12, n_estimators=75)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGLM+QLORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                6.7               2.8                5.7               2.3   \n",
      "1                7.1               2.8                6.3               2.5   \n",
      "2                5.1               3.5                1.5               0.2   \n",
      "3                6.7               3.3                5.8               2.5   \n",
      "4                5.1               3.8                1.7               0.2   \n",
      "\n",
      "   target  \n",
      "0     2.0  \n",
      "1     2.0  \n",
      "2     0.0  \n",
      "3     2.0  \n",
      "4     0.0  \n",
      "Logistic Regression Accuracy: 0.9666666666666667\n",
      "Decision Tree Accuracy: 0.9333333333333333\n",
      "Random Forest Accuracy: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/sample_data/model_finetune/chatglm3_6B_qlora.csv')\n",
    "data['target'] = data['target'].apply(lambda x: x if x in [1.0, 2.0] else 0)\n",
    "# data = pd.read_csv('/data/guoquanjiang/be_great/sample_data/california_samples.csv')\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "# X = data.drop('Class', axis=1)\n",
    "# y = data['Class']\n",
    "# Encode categorical features with Label Encoding\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode target column if it is categorical\n",
    "if y.dtype == 'object':\n",
    "    target_le = LabelEncoder()\n",
    "    y = target_le.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=100)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy}')\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(max_depth=600)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(max_depth=12, n_estimators=75)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGLM+DORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                6.7               2.8                5.7               2.3   \n",
      "1                7.1               3.4                6.3               2.3   \n",
      "2                5.0               3.5                1.5               0.2   \n",
      "3                6.7               3.3                5.8               2.5   \n",
      "4                5.1               3.4                1.5               0.2   \n",
      "\n",
      "   target  \n",
      "0     2.0  \n",
      "1     2.0  \n",
      "2     0.0  \n",
      "3     2.0  \n",
      "4     1.0  \n",
      "Logistic Regression Accuracy: 0.9333333333333333\n",
      "Decision Tree Accuracy: 0.8666666666666667\n",
      "Random Forest Accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/sample_data/model_finetune/chatglm3_6B_dora.csv')\n",
    "data['target'] = data['target'].apply(lambda x: x if x in [1.0, 2.0] else 0)\n",
    "# data = pd.read_csv('/data/guoquanjiang/be_great/sample_data/california_samples.csv')\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "# X = data.drop('Class', axis=1)\n",
    "# y = data['Class']\n",
    "# Encode categorical features with Label Encoding\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode target column if it is categorical\n",
    "if y.dtype == 'object':\n",
    "    target_le = LabelEncoder()\n",
    "    y = target_le.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=100)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy}')\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(max_depth=600)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(max_depth=12, n_estimators=75)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mistral+LORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                6.3               2.7                4.9               1.8   \n",
      "1                4.9               2.5                4.5               1.7   \n",
      "2                5.0               3.5                1.6               0.6   \n",
      "3                5.0               3.4                1.5               0.2   \n",
      "4                5.1               3.4                1.5               0.2   \n",
      "\n",
      "   target  \n",
      "0     2.0  \n",
      "1     2.0  \n",
      "2     0.0  \n",
      "3     0.0  \n",
      "4     0.0  \n",
      "Logistic Regression Accuracy: 0.9666666666666667\n",
      "Decision Tree Accuracy: 0.9333333333333333\n",
      "Random Forest Accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/sample_data/model_finetune/mistral_7B_lora.csv')\n",
    "# data = pd.read_csv('/data/guoquanjiang/be_great/sample_data/california_samples.csv')\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "# X = data.drop('Class', axis=1)\n",
    "# y = data['Class']\n",
    "# Encode categorical features with Label Encoding\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode target column if it is categorical\n",
    "if y.dtype == 'object':\n",
    "    target_le = LabelEncoder()\n",
    "    y = target_le.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=100)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy}')\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(max_depth=600)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(max_depth=12, n_estimators=75)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mistral+QLORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                7.2               3.2                6.0               1.8   \n",
      "1                5.4               3.9                1.7               0.4   \n",
      "2                6.3               2.7                4.9               1.8   \n",
      "3                5.1               3.8                1.5               0.3   \n",
      "4                4.9               2.5                4.5               1.7   \n",
      "\n",
      "   target  \n",
      "0     2.0  \n",
      "1     0.0  \n",
      "2     2.0  \n",
      "3     0.0  \n",
      "4     2.0  \n",
      "Logistic Regression Accuracy: 1.0\n",
      "Decision Tree Accuracy: 0.9\n",
      "Random Forest Accuracy: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/sample_data/model_finetune/mistral_7B_qlora.csv')\n",
    "# data = pd.read_csv('/data/guoquanjiang/be_great/sample_data/california_samples.csv')\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "# X = data.drop('Class', axis=1)\n",
    "# y = data['Class']\n",
    "# Encode categorical features with Label Encoding\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode target column if it is categorical\n",
    "if y.dtype == 'object':\n",
    "    target_le = LabelEncoder()\n",
    "    y = target_le.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=100)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy}')\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(max_depth=600)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(max_depth=12, n_estimators=75)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mistral+DORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                6.3               2.7                4.9               1.8   \n",
      "1                5.0               3.3                1.4               0.2   \n",
      "2                5.2               3.5                1.5               0.2   \n",
      "3                5.2               3.5                1.5               0.2   \n",
      "4                6.7               3.1                5.6               2.4   \n",
      "\n",
      "   target  \n",
      "0     2.0  \n",
      "1     0.0  \n",
      "2     0.0  \n",
      "3     0.0  \n",
      "4     2.0  \n",
      "Logistic Regression Accuracy: 0.9666666666666667\n",
      "Decision Tree Accuracy: 0.9666666666666667\n",
      "Random Forest Accuracy: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/sample_data/model_finetune/mistral_7B_dora.csv')\n",
    "# data = pd.read_csv('/data/guoquanjiang/be_great/sample_data/california_samples.csv')\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "# X = data.drop('Class', axis=1)\n",
    "# y = data['Class']\n",
    "# Encode categorical features with Label Encoding\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode target column if it is categorical\n",
    "if y.dtype == 'object':\n",
    "    target_le = LabelEncoder()\n",
    "    y = target_le.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=100)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy}')\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(max_depth=600)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(max_depth=12, n_estimators=75)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LlaMA2+LORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                6.4               3.1                5.6               2.4   \n",
      "1                5.8               2.7                5.1               1.9   \n",
      "2                6.3               2.3                4.4               1.3   \n",
      "3                6.5               2.5                5.5               1.8   \n",
      "4                5.1               3.8                1.6               0.2   \n",
      "\n",
      "   target  \n",
      "0     2.0  \n",
      "1     1.0  \n",
      "2     1.0  \n",
      "3     1.0  \n",
      "4     1.0  \n",
      "Logistic Regression Accuracy: 0.8\n",
      "Decision Tree Accuracy: 0.8333333333333334\n",
      "Random Forest Accuracy: 0.8666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/guoquanjiang/envs/begreat/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/sample_data/model_finetune/llama2_7B_lora.csv')\n",
    "data['target'] = data['target'].apply(lambda x: x if x in [1.0, 2.0] else 0)\n",
    "# data = pd.read_csv('/data/guoquanjiang/be_great/sample_data/california_samples.csv')\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "# X = data.drop('Class', axis=1)\n",
    "# y = data['Class']\n",
    "# Encode categorical features with Label Encoding\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode target column if it is categorical\n",
    "if y.dtype == 'object':\n",
    "    target_le = LabelEncoder()\n",
    "    y = target_le.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=100)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy}')\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(max_depth=600)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(max_depth=12, n_estimators=75)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LlaMA2+QLORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                6.5               3.0                5.2               2.0   \n",
      "1                6.3               2.7                4.9               1.8   \n",
      "2                6.7               3.3                5.7               2.5   \n",
      "3                6.7               3.0                5.8               2.2   \n",
      "4                5.8               2.7                5.1               1.9   \n",
      "\n",
      "   target  \n",
      "0     2.0  \n",
      "1     1.0  \n",
      "2     2.0  \n",
      "3     2.0  \n",
      "4     2.0  \n",
      "Logistic Regression Accuracy: 0.9\n",
      "Decision Tree Accuracy: 0.9333333333333333\n",
      "Random Forest Accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/sample_data/model_finetune/llama2_7B_qlora.csv')\n",
    "data['target'] = data['target'].apply(lambda x: x if x in [1.0, 2.0] else 0)\n",
    "# data = pd.read_csv('/data/guoquanjiang/be_great/sample_data/california_samples.csv')\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "# X = data.drop('Class', axis=1)\n",
    "# y = data['Class']\n",
    "# Encode categorical features with Label Encoding\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode target column if it is categorical\n",
    "if y.dtype == 'object':\n",
    "    target_le = LabelEncoder()\n",
    "    y = target_le.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=100)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy}')\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(max_depth=600)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(max_depth=12, n_estimators=75)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LlaMA2+DORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                6.4               3.1                5.6               2.4   \n",
      "1                5.2               3.5                1.5               0.2   \n",
      "2                5.1               3.8                1.6               0.2   \n",
      "3                6.3               2.9                5.6               2.3   \n",
      "4                6.0               2.9                4.5               1.5   \n",
      "\n",
      "   target  \n",
      "0     2.0  \n",
      "1     1.0  \n",
      "2     1.0  \n",
      "3     2.0  \n",
      "4     1.0  \n",
      "Logistic Regression Accuracy: 0.8333333333333334\n",
      "Decision Tree Accuracy: 0.9\n",
      "Random Forest Accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/sample_data/model_finetune/llama2_7B_dora.csv')\n",
    "data['target'] = data['target'].apply(lambda x: x if x in [1.0, 2.0] else 0)\n",
    "# data = pd.read_csv('/data/guoquanjiang/be_great/sample_data/california_samples.csv')\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "# X = data.drop('Class', axis=1)\n",
    "# y = data['Class']\n",
    "# Encode categorical features with Label Encoding\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode target column if it is categorical\n",
    "if y.dtype == 'object':\n",
    "    target_le = LabelEncoder()\n",
    "    y = target_le.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=100)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy}')\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(max_depth=600)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(max_depth=12, n_estimators=75)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LlaMA3+LORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                6.3               2.7                4.9               1.8   \n",
      "1                5.1               3.7                1.5               0.4   \n",
      "2                6.8               3.0                5.5               2.1   \n",
      "3                6.1               2.8                4.0               1.3   \n",
      "4                4.4               3.0                1.3               0.2   \n",
      "\n",
      "   target  \n",
      "0     1.0  \n",
      "1     0.0  \n",
      "2     2.0  \n",
      "3     2.0  \n",
      "4     0.0  \n",
      "Logistic Regression Accuracy: 0.6333333333333333\n",
      "Decision Tree Accuracy: 0.6666666666666666\n",
      "Random Forest Accuracy: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/guoquanjiang/envs/begreat/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/sample_data/model_finetune/llama3_8B_lora.csv')\n",
    "# data = pd.read_csv('/data/guoquanjiang/be_great/sample_data/california_samples.csv')\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "# X = data.drop('Class', axis=1)\n",
    "# y = data['Class']\n",
    "# Encode categorical features with Label Encoding\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode target column if it is categorical\n",
    "if y.dtype == 'object':\n",
    "    target_le = LabelEncoder()\n",
    "    y = target_le.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=100)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy}')\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(max_depth=600)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(max_depth=12, n_estimators=75)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LlaMA3+QLORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                6.9               3.1                5.1               2.3   \n",
      "1                6.3               2.7                4.9               1.8   \n",
      "2                4.6               3.1                1.5               0.2   \n",
      "3                5.6               2.5                3.9               1.1   \n",
      "4                6.1               2.8                4.0               1.3   \n",
      "\n",
      "   target  \n",
      "0     1.0  \n",
      "1     2.0  \n",
      "2     1.0  \n",
      "3     0.0  \n",
      "4     2.0  \n",
      "Logistic Regression Accuracy: 0.612565445026178\n",
      "Decision Tree Accuracy: 0.5497382198952879\n",
      "Random Forest Accuracy: 0.5392670157068062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/guoquanjiang/envs/begreat/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/sample_data/model_finetune/llama3_8B_qlora.csv')\n",
    "# data = pd.read_csv('/data/guoquanjiang/be_great/sample_data/california_samples.csv')\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "# X = data.drop('Class', axis=1)\n",
    "# y = data['Class']\n",
    "# Encode categorical features with Label Encoding\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode target column if it is categorical\n",
    "if y.dtype == 'object':\n",
    "    target_le = LabelEncoder()\n",
    "    y = target_le.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=100)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy}')\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(max_depth=600)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(max_depth=12, n_estimators=75)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LlaMA3+DORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.4               3.4                1.5               0.4   \n",
      "1                6.1               2.8                4.0               1.3   \n",
      "2                5.0               3.4                1.6               0.4   \n",
      "3                5.2               3.4                1.4               0.2   \n",
      "4                4.9               2.4                3.3               1.0   \n",
      "\n",
      "   target  \n",
      "0     0.0  \n",
      "1     2.0  \n",
      "2     0.0  \n",
      "3     0.0  \n",
      "4     0.0  \n",
      "Logistic Regression Accuracy: 0.5666666666666667\n",
      "Decision Tree Accuracy: 0.5666666666666667\n",
      "Random Forest Accuracy: 0.5666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/guoquanjiang/envs/begreat/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/Windows 11/Desktop/Dissertation/Codes/sample_data/model_finetune/llama3_8B_dora.csv')\n",
    "# data = pd.read_csv('/data/guoquanjiang/be_great/sample_data/california_samples.csv')\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "# X = data.drop('Class', axis=1)\n",
    "# y = data['Class']\n",
    "# Encode categorical features with Label Encoding\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode target column if it is categorical\n",
    "if y.dtype == 'object':\n",
    "    target_le = LabelEncoder()\n",
    "    y = target_le.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=100)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy}')\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(max_depth=600)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(max_depth=12, n_estimators=75)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
